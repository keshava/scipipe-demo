package main

import (
	"github.com/scipipe/scipipe"
	"github.com/scipipe/scipipe/components"
)

//class ExistingSmiles(sl.ExternalTask):
//    '''External task for getting hand on existing smiles files'''
//
//    # PARAMETERS
//    dataset_name = luigi.Parameter()
//
//    # TARGETS
//    def out_smiles(self):
//        datapath = os.path.abspath('./data')
//        filename = self.dataset_name + '.smi'
//        outfile_path = os.path.join(datapath, filename)
//        smilestgt = sl.TargetInfo(self, outfile_path)
//        return smilestgt
//
//# ====================================================================================================

type ExistingSmiles struct {
	BaseProcess scipipe.WorkflowProcess
}

func NewExistingSmiles(wf *scipipe.Workflow, name string) *ExistingSmiles {
	bp := components.NewFileSource(wf, name, "")
	return &ExistingSmiles{BaseProcess: bp}
}

//class GenerateSignaturesFilterSubstances(sl.SlurmTask):
//
//    # TASK PARAMETERS
//    min_height = luigi.IntParameter()
//    max_height = luigi.IntParameter()
//    silent_mode = luigi.BooleanParameter(default=True)
//
//    # INPUT TARGETS
//    in_smiles = None
//
//    # DEFINE OUTPUTS
//    def out_signatures(self):
//        return sl.TargetInfo(self, self.in_smiles().path + '.h%d_%d.sign' % (self.min_height, self.max_height))
//
//    # WHAT THE TASK DOES
//    def run(self):
//        self.ex(['java', '-jar', 'bin/GenerateSignatures.jar',
//                '-inputfile', self.in_smiles().path,
//                '-threads', self.slurminfo.threads,
//                '-minheight', str(self.min_height),
//                '-maxheight', str(self.max_height),
//                '-outputfile', self.out_signatures().path,
//                '-silent' if self.silent_mode else ''])
//        self.ex_local(['touch', self.out_signatures().path])
//
//# ====================================================================================================
//
//class UnGzipFile(sl.SlurmTask):
//    # TARGETS
//    in_gzipped = None
//
//    def out_ungzipped(self):
//        return sl.TargetInfo(self, self.in_gzipped().path + '.ungz')
//
//    def run(self):
//        self.ex(['gunzip', '-c',
//                  self.in_gzipped().path,
//                  '>',
//                  self.out_ungzipped().path])
//
//# ====================================================================================================
//
//class CreateRunCopy(sl.Task):
//
//    # TASK PARAMETERS
//    run_id = luigi.Parameter()
//
//    # TARGETS
//    in_file = None
//
//    def out_copy(self):
//        filedir = os.path.dirname(self.in_file().path)
//        filename = os.path.basename(self.in_file().path)
//        newdir = os.path.join(filedir, self.run_id)
//        if not os.path.isdir(newdir):
//            os.mkdir(newdir)
//        return sl.TargetInfo(self, os.path.join(newdir, filename))
//
//    def run(self):
//        shutil.copy(self.in_file().path, self.out_copy().path)
//
//# ====================================================================================================
//
//class CreateReplicateCopy(sl.Task):
//
//    # TASK PARAMETERS
//    replicate_id = luigi.Parameter()
//
//    # TARGETS
//    in_file = None
//
//    def out_copy(self):
//        if self.in_file is None:
//            raise Exception('In-port field in_file of CreateReplicateCopy is None')
//        elif self.in_file() is None:
//            raise Exception('In-port field in_file of CreateReplicateCopy return None')
//        else:
//            return sl.TargetInfo(self, self.in_file().path + '.' + self.replicate_id)
//
//    def run(self):
//        shutil.copy(self.in_file().path, self.out_copy().path)
//
//# ====================================================================================================
//
//class SampleTrainAndTest(sl.SlurmTask):
//
//    # TASK PARAMETERS
//    seed = luigi.Parameter(default=None)
//    test_size = luigi.Parameter()
//    train_size = luigi.Parameter()
//    sampling_method = luigi.Parameter()
//    replicate_id = luigi.Parameter()
//
//    # INPORTS
//    in_signatures = None
//
//    # OUTPORTS
//    def out_traindata(self):
//        return sl.TargetInfo(self, self.get_basepath() + '_trn')
//    def out_testdata(self):
//        return sl.TargetInfo(self, self.get_basepath() + '_tst')
//    def out_log(self):
//        return sl.TargetInfo(self, self.get_basepath() + '_trn.log') # This is generated by the jar
//    # OUTPORT Helper method
//    def get_basepath(self):
//        base_path = self.in_signatures().path + '.{test}_{train}_{method}'.format(
//            test  = self.test_size.replace('%', 'proc'),
//            train = self.train_size,
//            method = self.sampling_method.replace('random', 'rand').replace('signature_count', 'signcnt'))
//        return base_path
//
//    # WHAT THE TASK DOES
//    def run(self):
//        test_temp_path  = self.out_testdata().path  + '.tmp'
//        train_temp_path = self.out_traindata().path + '.tmp'
//
//        jar_files = { 'random'          : 'SampleTrainingAndTest',
//                      'signature_count' : 'SampleTrainingAndTestSizedBased' }
//        jar_file = jar_files[self.sampling_method]
//
//        cmd = ['java', '-jar', 'bin/' + jar_file + '.jar',
//                     '-inputfile', self.in_signatures().path,
//                     '-testfile', test_temp_path,
//                     '-trainingfile', train_temp_path,
//                     '-testsize', self.test_size,
//                     '-trainingsize', self.train_size,
//                     '-silent']
//        if self.seed is not None and self.seed != 'None':
//            cmd.extend(['-seed', self.seed])
//
//        self.ex(cmd)
//
//        # Restore temporary test and train files to their original file names
//        shutil.move(test_temp_path,
//                    self.out_testdata().path)
//        shutil.move(train_temp_path,
//                    self.out_traindata().path)
//        shutil.move(self.out_traindata().path + '.tmp.log',
//                    self.out_traindata().path + '.log')
//
//# ====================================================================================================
//
//class CreateSparseTrainDataset(sl.SlurmTask):
//
//    # TASK PARAMETERS
//    replicate_id = luigi.Parameter()
//
//    # INPUT TARGETS
//    in_traindata = None
//
//    def out_sparse_traindata(self):
//        return sl.TargetInfo(self, self.in_traindata().path + '.csr')
//
//    def out_signatures(self):
//        return sl.TargetInfo(self, self.in_traindata().path + '.signatures')
//
//    def out_log(self):
//        return sl.TargetInfo(self, self.in_traindata().path + '.csr.log')
//
//    # WHAT THE TASK DOES
//    def run(self):
//        self.ex(['java', '-jar', 'bin/CreateSparseDataset.jar',
//                '-inputfile', self.in_traindata().path,
//                '-datasetfile', self.out_sparse_traindata().path,
//                '-signaturesoutfile', self.out_signatures().path,
//                '-silent'])
//
//# ====================================================================================================
//
//class CreateSparseTestDataset(sl.Task):
//
//    # INPUT TARGETS
//    in_testdata = None
//    in_signatures = None
//
//    # TASK PARAMETERS
//    replicate_id = luigi.Parameter()
//    java_path = luigi.Parameter
//
//    # DEFINE OUTPUTS
//    def out_sparse_testdata(self):
//        return sl.TargetInfo(self, self.get_basepath()+ '.csr')
//    def out_signatures(self):
//        return sl.TargetInfo(self, self.get_basepath()+ '.signatures')
//    def out_log(self):
//        return sl.TargetInfo(self, self.get_basepath()+ '.csr.log')
//    def get_basepath(self):
//        return self.in_testdata().path
//
//    # WHAT THE TASK DOES
//    def run(self):
//        self.ex(['java', '-jar', 'bin/CreateSparseDataset.jar',
//                '-inputfile', self.in_testdata().path,
//                '-signaturesinfile', self.in_signatures().path,
//                '-datasetfile', self.out_sparse_testdata().path,
//                '-signaturesoutfile', self.out_signatures().path,
//                '-silent'])
//
//# ====================================================================================================
//
//class TrainSVMModel(sl.SlurmTask):
//
//    # INPUT TARGETS
//    in_traindata = None
//
//    # TASK PARAMETERS
//    replicate_id = luigi.Parameter()
//    train_size = luigi.Parameter()
//    svm_gamma = luigi.Parameter()
//    svm_cost = luigi.Parameter()
//    svm_type = luigi.Parameter()
//    svm_kernel_type = luigi.Parameter()
//
//    # Whether to run svm-train or pisvm-train when training
//    parallel_train = luigi.BooleanParameter()
//
//    # DEFINE OUTPUTS
//    def out_model(self):
//        return sl.TargetInfo(self, self.in_traindata().path + '.g{g}_c{c}_s{s}_t{t}.svm'.format(
//            g = self.svm_gamma.replace('.', 'p'),
//            c = self.svm_cost,
//            s = self.svm_type,
//            t = self.svm_kernel_type))
//
//    def out_traintime(self):
//        return sl.TargetInfo(self, self.out_model().path + '.extime')
//
//    # WHAT THE TASK DOES
//    def run(self):
//        '''
//        Determine pisvm parameters based on training set size
//        Details from Ola and Marcus:
//
//        size         o    q
//        -------------------
//        <1k:       100  100
//        1k-5k:     512  256
//        5k-40k    1024 1024
//        >40k      2048 2048
//        '''
//
//        train_size = self.train_size
//        if train_size == 'rest':
//            o = 2048
//            q = 2048
//        else:
//            trainsize_num = int(train_size)
//            if trainsize_num < 100:
//                o = 10
//                q = 10
//            elif 100 <= trainsize_num < 1000:
//                o = 100
//                q = 100
//            elif 1000 <= trainsize_num < 5000:
//                o = 512
//                q = 256
//            elif 5000 <= trainsize_num < 40000:
//                o = 1024
//                q = 1024
//            elif 40000 <= trainsize_num:
//                o = 2048
//                q = 2048
//            else:
//                raise Exception('Trainingsize {s} is not "rest" nor a valid positive number!'.format(s = trainsize_num))
//
//        # Set some file paths
//        trainfile = self.in_traindata().path
//        svmmodel_file = self.out_model().path
//
//        # Select train command based on parameter
//        if self.parallel_train:
//            self.ex(['/usr/bin/time', '-f%e', '-o',
//                    self.out_traintime().path,
//                    'bin/pisvm-train',
//                    '-o', str(o),
//                    '-q', str(q),
//                    '-s', self.svm_type,
//                    '-t', self.svm_kernel_type,
//                    '-g', self.svm_gamma,
//                    '-c', self.svm_cost,
//                    '-m', '2000',
//                    self.in_traindata().path,
//                    svmmodel_file,
//                    '>',
//                    '/dev/null']) # Needed, since there is no quiet mode in pisvm :/
//        else:
//            self.ex(['/usr/bin/time', '-f%e', '-o',
//                self.out_traintime().path,
//                'bin/svm-train',
//                '-s', self.svm_type,
//                '-t', self.svm_kernel_type,
//                '-g', self.svm_gamma,
//                '-c', self.svm_cost,
//                '-m', '2000',
//                '-q', # quiet mode
//                self.in_traindata().path,
//                svmmodel_file])
//
//# ====================================================================================================
//
//class TrainLinearModel(sl.SlurmTask):
//    # INPUT TARGETS
//    in_traindata = None
//
//    # TASK PARAMETERS
//    replicate_id = luigi.Parameter()
//    lin_type = luigi.Parameter() # 0 (regression)
//    lin_cost = luigi.Parameter() # 100
//    # Let's wait with implementing these
//    #lin_epsilon = luigi.Parameter()
//    #lin_bias = luigi.Parameter()
//    #lin_weight = luigi.Parameter()
//    #lin_folds = luigi.Parameter()
//
//    # Whether to run normal or distributed lib linear
//    #parallel_train = luigi.BooleanParameter()
//
//    # DEFINE OUTPUTS
//    def out_model(self):
//        return sl.TargetInfo(self, self.in_traindata().path + '.s{s}_c{c}.linmdl'.format(
//            s = self.lin_type,
//            c = self.lin_cost))
//
//    def out_traintime(self):
//        return sl.TargetInfo(self, self.out_model().path + '.extime')
//
//    # WHAT THE TASK DOES
//    def run(self):
//        #self.ex(['distlin-train',
//        self.ex(['/usr/bin/time', '-f%e', '-o',
//            self.out_traintime().path,
//            'bin/lin-train',
//            '-s', self.lin_type,
//            '-c', self.lin_cost,
//            '-q', # quiet mode
//            self.in_traindata().path,
//            self.out_model().path])
//
//# ====================================================================================================
//
//class PredictSVMModel(sl.Task):
//    # INPUT TARGETS
//    in_svmmodel = None
//    in_sparse_testdata = None
//    replicate_id = luigi.Parameter()
//
//    # TASK PARAMETERS
//    testdata_gzipped = luigi.BooleanParameter(default=True)
//
//    # DEFINE OUTPUTS
//    def out_prediction(self):
//        return sl.TargetInfo(self, self.in_svmmodel().path + '.pred')
//
//    # WHAT THE TASK DOES
//    def run(self):
//        # Run prediction
//        self.ex(['bin/svm-predict',
//                self.in_sparse_testdata().path,
//                self.in_svmmodel().path,
//                self.out_prediction().path])
//
//# ====================================================================================================
//
//class PredictLinearModel(sl.Task):
//    # INPUT TARGETS
//    in_model = None
//    in_sparse_testdata = None
//
//    # TASK PARAMETERS
//    replicate_id = luigi.Parameter()
//
//    # DEFINE OUTPUTS
//    def out_prediction(self):
//        return sl.TargetInfo(self, self.in_model().path + '.pred')
//
//    # WHAT THE TASK DOES
//    def run(self):
//        self.ex(['bin/lin-predict',
//            self.in_sparse_testdata().path,
//            self.in_model().path,
//            self.out_prediction().path])
//
//# ====================================================================================================
//
//class AssessLinearRMSD(sl.Task): # TODO: Check with Jonalv whether RMSD is what we want to do?!!
//    # Parameters
//    lin_cost = luigi.Parameter()
//
//    # INPUT TARGETS
//    in_model = None
//    in_sparse_testdata = None
//    in_prediction = None
//
//    # DEFINE OUTPUTS
//    def out_assessment(self):
//        return sl.TargetInfo(self, self.in_prediction().path + '.rmsd')
//
//    # WHAT THE TASK DOES
//    def run(self):
//        with self.in_sparse_testdata().open() as testfile:
//            with self.in_prediction().open() as predfile:
//                squared_diffs = []
//                for tline, pline in zip(testfile, predfile):
//                    test = float(tline.split(' ')[0])
//                    pred = float(pline)
//                    squared_diff = (pred-test)**2
//                    squared_diffs.append(squared_diff)
//        rmsd = math.sqrt(sum(squared_diffs)/len(squared_diffs))
//        rmsd_records = {'rmsd': rmsd,
//                        'cost': self.lin_cost}
//        with self.out_assessment().open('w') as assessfile:
//            sl.util.dict_to_recordfile(assessfile, rmsd_records)
//
//# ====================================================================================================
//
//class AssessSVMRMSD(sl.Task):
//    # Parameters
//    svm_cost = luigi.Parameter()
//    svm_gamma = luigi.Parameter()
//    svm_type = luigi.Parameter()
//    svm_kernel_type = luigi.Parameter()
//
//    # INPUT TARGETS
//    in_model = None
//    in_sparse_testdata = None
//    in_prediction = None
//
//    # DEFINE OUTPUTS
//    def out_assessment(self):
//        return sl.TargetInfo(self, self.in_prediction().path + '.rmsd')
//
//    # WHAT THE TASK DOES
//    def run(self):
//        with self.in_sparse_testdata().open() as testfile:
//            with self.in_prediction().open() as predfile:
//                squared_diffs = []
//                for tline, pline in zip(testfile, predfile):
//                    test = float(tline.split(' ')[0])
//                    pred = float(pline)
//                    squared_diff = (pred-test)**2
//                    squared_diffs.append(squared_diff)
//        rmsd = math.sqrt(sum(squared_diffs)/len(squared_diffs))
//        rmsd_records = {'rmsd': rmsd,
//                        'svm_cost': self.svm_cost,
//                        'svm_gamma': self.svm_gamma,
//                        'svm_type': self.svm_type,
//                        'svm_kernel_type': self.svm_kernel_type}
//        with self.out_assessment().open('w') as assessfile:
//            sl.util.dict_to_recordfile(assessfile, rmsd_records)
//
//# ====================================================================================================
//
//class CollectDataReportRow(sl.Task):
//    dataset_name = luigi.Parameter()
//    train_method = luigi.Parameter()
//    train_size = luigi.Parameter()
//    replicate_id = luigi.Parameter()
//    lin_cost = luigi.Parameter()
//
//    in_rmsd = None
//    in_traintime = None
//    in_trainsize_filtered = None
//
//    def out_datareport_row(self):
//        outdir = os.path.dirname(self.in_rmsd().path)
//        return sl.TargetInfo(self, os.path.join(outdir, '{ds}_{lm}_{ts}_{ri}_datarow.txt'.format(
//                    ds=self.dataset_name,
//                    lm=self.train_method,
//                    ts=self.train_size,
//                    ri=self.replicate_id
//                )))
//
//    def run(self):
//        with self.in_rmsd().open() as rmsdfile:
//            rmsddict = sl.recordfile_to_dict(rmsdfile)
//            rmsd = rmsddict['rmsd']
//
//        with self.in_traintime().open() as traintimefile:
//            train_time_sec = traintimefile.read().rstrip('\n')
//
//        with self.in_trainsize_filtered().open() as trainsizefile:
//            train_size_filtered = trainsizefile.read().strip('\n')
//
//        if self.lin_cost is not None:
//            lin_cost = self.lin_cost
//        else:
//            lin_cost = 'NA'
//
//        with self.out_datareport_row().open('w') as outfile:
//            rdata = { 'dataset_name': self.dataset_name,
//                      'train_method': self.train_method,
//                      'train_size': self.train_size,
//                      'train_size_filtered': train_size_filtered,
//                      'replicate_id': self.replicate_id,
//                      'rmsd': rmsd,
//                      'train_time_sec': train_time_sec,
//                      'lin_cost': lin_cost}
//            sl.dict_to_recordfile(outfile, rdata)
//
//# ====================================================================================================
//
//class CollectDataReport(sl.Task):
//    dataset_name = luigi.Parameter()
//    train_method = luigi.Parameter()
//
//    in_datareport_rows = None
//
//    def out_datareport(self):
//        outdir = os.path.dirname(self.in_datareport_rows[0]().path)
//        return sl.TargetInfo(self, os.path.join(outdir, '{ds}_{tm}_datareport.csv'.format(
//                    ds=self.dataset_name,
//                    tm=self.train_method
//               )))
//
//    def run(self):
//        with self.out_datareport().open('w') as outfile:
//            csvwrt = csv.writer(outfile)
//            # Write header
//            csvwrt.writerow(['dataset_name',
//                             'train_method',
//                             'train_size',
//                             'train_size_filtered',
//                             'replicate_id',
//                             'rmsd',
//                             'train_time_sec',
//                             'lin_cost'])
//            # Write data rows
//            for intargetinfofunc in self.in_datareport_rows:
//                with intargetinfofunc().open() as infile:
//                    r = sl.recordfile_to_dict(infile)
//                    csvwrt.writerow([r['dataset_name'],
//                                     r['train_method'],
//                                     r['train_size'],
//                                     r['train_size_filtered'],
//                                     r['replicate_id'],
//                                     r['rmsd'],
//                                     r['train_time_sec'],
//                                     r['lin_cost']])
//
//# ====================================================================================================
//
//class CalcAverageRMSDForCost(sl.Task): # TODO: Check with Jonalv whether RMSD is what we want to do?!!
//    # Parameters
//    lin_cost = luigi.Parameter()
//
//    # Inputs
//    in_assessments = None
//
//    # output
//    def out_rmsdavg(self):
//        return sl.TargetInfo(self, self.in_assessments[0]().path + '.avg')
//
//    def run(self):
//        vals = []
//        for invalfun in self.in_assessments:
//            infile = invalfun().open()
//            records = sl.util.recordfile_to_dict(infile)
//            vals.append(float(records['rmsd']))
//        rmsdavg = sum(vals)/len(vals)
//        rmsdavg_records = {'rmsd_avg': rmsdavg,
//                           'cost': self.lin_cost}
//        with self.out_rmsdavg().open('w') as outfile:
//            sl.util.dict_to_recordfile(outfile, rmsdavg_records)
//
//# ====================================================================================================
//
//class SelectLowestRMSD(sl.Task):
//    # Inputs
//    in_values = None
//
//    # output
//    def out_lowest(self):
//        cost_part = '.c' + hashlib.md5('_'.join([v().task.lin_cost for v in self.in_values])).hexdigest()
//        return sl.TargetInfo(self, self.in_values[0]().path + cost_part + '.min')
//
//    def run(self):
//        vals = []
//        for invalfun in self.in_values:
//            infile = invalfun().open()
//            records = sl.util.recordfile_to_dict(infile)
//            vals.append(records)
//
//        lowest_rmsd = float(min(vals, key=lambda v: float(v['rmsd_avg']))['rmsd_avg'])
//        vals_lowest_rmsd = [v for v in vals if float(v['rmsd_avg']) <= lowest_rmsd]
//        val_lowest_rmsd_cost = min(vals_lowest_rmsd, key=lambda v: v['cost'])
//        lowestrec = {'lowest_rmsd_avg': val_lowest_rmsd_cost['rmsd_avg'],
//                     'lowest_cost': val_lowest_rmsd_cost['cost']}
//        with self.out_lowest().open('w') as lowestfile:
//            sl.util.dict_to_recordfile(lowestfile, lowestrec)
//
//# ====================================================================================================
//
//class CreateElasticNetModel(sl.Task):
//
//    # INPUT TARGETS
//    in_traindata = None
//
//    # TASK PARAMETERS
//    l1_value = luigi.Parameter()
//    lambda_value = luigi.Parameter()
//    java_path = luigi.Parameter()
//
//    # DEFINE OUTPUTS
//    def out_model(self):
//        return sl.TargetInfo(self, self.in_traindata().path + '.model_{l}_{y}'.format(
//            l=self.get_value('l1_value'),
//            y=self.get_value('lambda_value')
//        ))
//
//    def run(self):
//        self.ex(['java', '-jar', 'bin/CreateElasticNetModel.jar',
//                '-inputfile', self.in_traindata().path,
//                '-l1ratio', str(self.get_value('l1_value')),
//                '-lambda', str(self.get_value('lambda_value')),
//                '-outputfile', self.out_model().path,
//                '-silent'])
//
//        #self.ex_local(['mv',
//        #         self.in_traindata().path + '.model',
//        #         self.in_traindata().path + '.model_{l}_{y}'.format(l=self.get_value('l1_value'),y=self.get_value('lambda_value'))])
//
//
//# ====================================================================================================
//
//class PredictElasticNetModel(sl.Task):
//
//    # INPUT TARGETS
//    in_elasticnet_model = None
//    in_testdata = None
//
//    # TASK PARAMETERS
//    l1_value = luigi.Parameter()
//    lambda_value = luigi.Parameter()
//    java_path = luigi.Parameter()
//
//    def out_prediction(self):
//        return sl.TargetInfo(self, self.in_elasticnet_model().path + '.pred')
//
//    def run(self):
//        self.ex(['java', '-jar', 'bin/PredictElasticNetModel.jar',
//                '-modelfile', self.in_elasticnet_model().path,
//                '-testset', self.in_testdata().path,
//                '-outputfile', self.out_prediction().path,
//                '-silent'])
//
//# ====================================================================================================
//
//class EvaluateElasticNetPrediction(sl.Task):
//     # INPUT TARGETS
//     in_testdata = None
//     in_prediction = None
//
//     # TASK PARAMETERS
//     l1_value = luigi.Parameter()
//     lambda_value = luigi.Parameter()
//
//     # DEFINE OUTPUTS
//     def out_evaluation(self):
//         return sl.TargetInfo(self,  self.in_prediction().path + '.evaluation' )
//
//     # WHAT THE TASK DOES
//     def run(self):
//         with gzip.open(self.in_testdata().path) as testset_file, self.in_prediction().open() as prediction_file:
//             original_vals = [float(line.split(' ')[0]) for line in testset_file]
//             predicted_vals = [float(val.strip('\n')) for val in prediction_file]
//         squared = [(pred-orig)**2 for orig, pred in zip(original_vals, predicted_vals)]
//         rmsd = math.sqrt( sum(squared) / len(squared) )
//         with self.out_evaluation().open('w') as outfile:
//             csvwriter = csv.writer(outfile)
//             csvwriter.writerow(['rmsd', rmsd])
//             csvwriter.writerow(['l1ratio', self.get_value('l1_value')])
//             csvwriter.writerow(['lambda', self.get_value('lambda_value')])
//
//# ====================================================================================================
//
//class CountLines(sl.SlurmTask):
//    ungzip = luigi.BooleanParameter(default=False)
//
//    in_file = None
//
//    def out_linecount(self):
//        return sl.TargetInfo(self, self.in_file().path + '.linecnt')
//
//    def run(self):
//        if self.ungzip:
//            cmd = 'zcat %s | wc -l' % self.in_file().path
//        else:
//            cmd = 'wc -l %s' % self.in_file().path
//
//        with self.in_file().open() as infile:
//            with self.out_linecount().open('w') as outfile:
//                stat, out, err = self.ex_local(cmd)
//                linecnt = int(out.split(' ')[0])
//                outfile.write(str(linecnt))
//
//# ====================================================================================================
//
//class CreateRandomData(sl.SlurmTask):
//    size_mb = luigi.IntParameter()
//    replicate_id = luigi.Parameter()
//
//    in_basepath = None
//
//    def out_random(self):
//        return sl.TargetInfo(self, self.in_basepath().path + '.randombytes')
//
//    def run(self):
//        cmd =['dd',
//              'if=/dev/urandom',
//              'of=%s' % self.out_random().path,
//              'bs=1048576',
//              'count=%d' % self.size_mb]
//        self.ex(cmd)
//
//# ====================================================================================================
//
//class ShuffleLines(sl.SlurmTask):
//    in_file = None
//    in_randomdata = None
//
//    def out_shuffled(self):
//        return sl.TargetInfo(self, self.in_file().path + '.shuf')
//
//    def run(self):
//        #with self.in_file().open() as infile:
//        #    with self.out_shuffled().open('w') as outfile:
//        self.ex(['shuf',
//                       '--random-source=%s' % self.in_randomdata().path,
//                       self.in_file().path,
//                       '>',
//                       self.out_shuffled().path])
//
//# ====================================================================================================
//
//class CreateFolds(sl.SlurmTask):
//
//    # TASK PARAMETERS
//    folds_count = luigi.IntParameter()
//    fold_index = luigi.IntParameter()
//
//    # TARGETS
//    in_dataset = None
//    in_linecount = None
//
//    def out_testdata(self):
//        return sl.TargetInfo(self, self.in_dataset().path + '.fld{0:02}_tst'.format(self.fold_index))
//
//    def out_traindata(self):
//        return sl.TargetInfo(self, self.in_dataset().path + '.fld{0:02}_trn'.format(self.fold_index))
//
//    def run(self):
//        with self.in_linecount().open() as linecntfile:
//            linecnt = int(linecntfile.read())
//
//        linesperfold = int(math.floor(linecnt / self.folds_count))
//        tst_start = self.fold_index * linesperfold
//        tst_end = (self.fold_index + 1) * linesperfold
//
//        # CREATE TEST FOLD
//        self.ex(['awk',
//                 '"NR >= %d && NR <= %d { print }"' % (tst_start, tst_end),
//                 self.in_dataset().path,
//                 '>',
//                 self.out_testdata().path])
//
//        # CREATE TRAIN FOLD
//        self.ex(['awk',
//                 '"NR < %d || NR > %d { print }"' % (tst_start, tst_end),
//                 self.in_dataset().path,
//                 '>',
//                 self.out_traindata().path])
//
//# ================================================================================
//
//class SelectPercentIndexValue(sl.Task):
//
//    # TASK PARAMETERS
//    percent_index = luigi.IntParameter()
//
//    # TARGETS
//    in_prediction = None
//
//    def out_indexvalue(self):
//        return sl.TargetInfo(self, self.in_prediction().path + '.idx{i:d}'.format(i=self.percent_index))
//
//    def run(self):
//        with self.in_prediction().open() as infile:
//            lines = [float(l) for l in infile.readlines()]
//            lines.sort()
//            linescnt = len(lines)
//            index = int(linescnt * (self.percent_index / 100.0))
//            indexval = lines[index]
//            with self.out_indexvalue().open('w') as outfile:
//                outfile.write('%f\n' % indexval)
//
//# ================================================================================
//
//class MergeOrigAndPredValues(sl.Task):
//    # TARGETS
//    in_original_dataset = lambda: sl.TargetInfo(None, None)
//    in_predicted_dataset = lambda: sl.TargetInfo(None, None)
//
//    def out_merged(self):
//        return sl.TargetInfo(self, self.in_original_dataset().path + '.merged')
//
//    def run(self):
//        with self.in_original_dataset().open() as origfile:
//            with self.in_predicted_dataset().open() as predfile:
//                with self.out_merged().open('w') as outfile:
//                    for orig, pred in zip(origfile, predfile):
//                        outfile.write(orig.split(' ')[0] + ', ' + pred + '\n')
//
//# ================================================================================
//
//class PlotCSV(sl.Task):
//    # TARGETS
//    in_csv = lambda: sl.TargetInfo(None, None)
//
//    xmin = luigi.Parameter()
//    xmax = luigi.Parameter()
//    ymin = luigi.Parameter()
//    ymax = luigi.Parameter()
//
//    def out_pdf(self):
//        return sl.TargetInfo(self, self.in_csv().path + '.pdf')
//
//    def run(self):
//        # Create a temporary R script
//        rscript = u'''
//        ## Parse arguments
//        library('argparse')
//        p <- ArgumentParser()
//        p$add_argument("-i", "--input", type="character",
//                       help="Input file in CSV format")
//        p$add_argument("-o", "--output", type="character",
//                       help="Output file (will be in .pdf format)")
//        args <- p$parse_args()
//
//        ## Plot
//        if ( args$input != "" && args$output != "" ) {{
//          data = read.csv(file=args$input, header = FALSE)
//          pdf(file = args$output, width=5, height=5)
//          plot(NULL, xlim=c({xmin},{xmax}), ylim=c({ymin},{ymax}), xlab="", ylab="", cex.axis=1.5)
//          points(data, cex = .2, pch=16)
//          dev.off()
//        }} else {{
//            print('Either input or output is missing! Use -h to see options!')
//            quit(1)
//        }}
//        '''.format(
//                xmin=self.xmin,
//                xmax=self.xmax,
//                ymin=self.ymin,
//                ymax=self.ymax)
//
//        tempscriptpath='.temp-r-script-%s.r' % uuid.uuid4()
//        tsf = open(tempscriptpath,'w')
//        tsf.write(rscript)
//        tsf.close()
//        # Execute the R script
//        self.ex_local(['xvfb-run',
//                       'Rscript',
//                       tempscriptpath,
//                       '-i',
//                       self.in_csv().path,
//                       '-o',
//                       self.out_pdf().path])
//        # Remove the temporary R script
//        self.ex_local(['rm',
//                       tempscriptpath])
//
//# ================================================================================
//
//class MergedDataReport(sl.Task):
//    run_id = luigi.Parameter()
//
//    in_reports = None
//
//    def out_merged_report(self):
//        return sl.TargetInfo(self, 'data/' + self.run_id + '_merged_report.csv')
//
//    def run(self):
//        merged_rows = []
//        for i, inreportfile_targetinfo in enumerate(self.in_reports):
//            infile = inreportfile_targetinfo().open()
//            for j, line in enumerate(infile):
//                if i == 0 and j == 0:
//                    merged_rows.append(line) # Append header
//                if j > 0:
//                    merged_rows.append(line)
//        with self.out_merged_report().open('w') as outfile:
//            outfile.write(''.join(merged_rows))
